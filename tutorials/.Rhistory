pretrainedModel = "clip-rsicd",
imageKeysOfUnits = KeysOfObservations[ take_indices ],
CleanupEnv = T)
# analyze Clip representations
plot( MyImageEmbeddings_Clip$ImageRepresentations  )
# sanity check - # of rows in MyImageEmbeddings matches # of image keys
nrow(MyImageEmbeddings_Clip$ImageRepresentations) == length(KeysOfObservations[ take_indices ])
# other output quantities include the image model functions and model parameters
names(  MyImageEmbeddings_Clip  )[-1]
print("Done with image representations tutorial!")
}
rm(list=ls()); options(error = NULL)
causalimages::BuildBackend()
causalimages::BuildBackend()
conda_list()
conda_binary()
conda info --envs
conda create --name CausalImagesEnv python=3.11
conda_list()
library(reticulate)
conda_list()
py_config()
conda_list()
py_config()
causalimages::BuildBackend()
use_condaenv("CausalImagesEnv", required = TRUE)
conda_binary()
causalimages::BuildBackend(conda = "/opt/anaconda3/bin/python")
causalimages::BuildBackend(conda = "/opt/anaconda3/bin/python")
causalimages::BuildBackend(conda = "auto")
rm(list = ls()); options(error = NULL)
causalimages::BuildBackend()
causalimages::BuildBackend()
rm(list = ls()); options(error = NULL)
causalimages::BuildBackend()
rm(list = ls()); options(error = NULL)
causalimages::BuildBackend()
py_config
library(reticulate)
py_config
causalimages::BuildBackend()
causalimages::BuildBackend()
rm(list=ls()); options(error = NULL)
#!/usr/bin/env Rscript
{
# clear workspace
rm(list=ls()); options(error = NULL)
################################
# Image confounding tutorial using causalimages & tfrecords
# remote install latest version of the package if needed
# devtools::install_github(repo = "cjerzak/causalimages-software/causalimages")
# local install for development team
# install.packages("~/Documents/causalimages-software/causalimages",repos = NULL, type = "source",force = F)
# build backend you haven't ready:
# causalimages::BuildBackend()
# load in package
library( causalimages  )
# load in tutorial data
data(  CausalImagesTutorialData )
# example acquire image function (loading from memory)
# in general, you'll want to write a function that returns images
# that saved disk associated with keys
acquireImageFromMemory <- function(keys){
# here, the function input keys
# refers to the unit-associated image keys
m_ <- FullImageArray[match(keys, KeysOfImages),,,]
# if keys == 1, add the batch dimension so output dims are always consistent
# (here in image case, dims are batch by height by width by channel)
if(length(keys) == 1){
m_ <- array(m_,dim = c(1L,dim(m_)[1],dim(m_)[2],dim(m_)[3]))
}
# uncomment for a test with different image dimensions
#if(length(keys) == 1){ m_ <- abind::abind(m_,m_,m_,along = 3L) }; if(length(keys) > 1){ m_ <- abind::abind(m_,m_,m_,.along = 4L) }
return( m_ )
}
dim( acquireImageFromMemory(KeysOfImages[1]) )
dim( acquireImageFromMemory(KeysOfImages[1:2]) )
# drop first column
X <- X[,-1]
# mean imputation for simplicity
X <- apply(X,2,function(zer){
zer[is.na(zer)] <- mean( zer,na.rm = T )
return( zer )
})
# select observation subset to make tutorial analyses run faster
# select 50 treatment and 50 control observations
set.seed(1.)
take_indices <- unlist( tapply(1:length(obsW),obsW,function(zer){sample(zer, 50)}) )
# !!! important note !!!
# when using tf recordings, it is essential that the data inputs be pre-shuffled like is done here.
# you can use a seed for reproducing the shuffle (so the tfrecord is correctly indexed and you don't need to re-make it)
# tf records read data quasi-sequentially, so systematic patterns in the data ordering
# reduce performance
# uncomment for a larger n analysis
#take_indices <- 1:length( obsY )
# set tfrecord save location (best to use absolute paths, but relative paths should in general work too)
tfrecord_loc <- "~/Downloads/ExampleRecord.tfrecord"
# write a tf records repository
causalimages::WriteTfRecord(  file = tfrecord_loc,
uniqueImageKeys = unique( as.character(KeysOfObservations)[ take_indices ] ),
acquireImageFxn = acquireImageFromMemory )
# perform causal inference with image and tabular confounding
# toy example for illustration purposes where
# treatment is truly randomized
ImageConfoundingAnalysis <- causalimages::AnalyzeImageConfounding(
obsW = obsW[ take_indices ],
obsY = obsY[ take_indices ],
X = X[ take_indices,apply(X[ take_indices,],2,sd)>0],
long = LongLat$geo_long[ take_indices ],
lat = LongLat$geo_lat[ take_indices ],
batchSize = 16L,
imageKeysOfUnits = as.character(KeysOfObservations)[ take_indices ],
file = tfrecord_loc, # point to tfrecords file
nSGD = 500L,
imageModelClass = "CNN",
#imageModelClass = "VisionTransformer",
plotBands = c(1,2,3),
figuresTag = "TutorialExample",
figuresPath = "~/Downloads/TFRecordTutorial" # figures saved here (use absolute file paths)
)
# ATE estimate (image confounder adjusted)
ImageConfoundingAnalysis$tauHat_propensityHajek
# ATE se estimate (image confounder adjusted)
ImageConfoundingAnalysis$tauHat_propensityHajek_se
# see figuresPath for image analysis output
causalimages::print2("Done with TfRecords tutorial!")
}
reticulate::py_last_error()
( acquireImageFromMemory(KeysOfImages[1:2]) )
dim( acquireImageFromMemory(KeysOfImages[1]) )
dim( acquireImageFromMemory(KeysOfImages[1:2]) )
# drop first column
X <- X[,-1]
# mean imputation for simplicity
X <- apply(X,2,function(zer){
zer[is.na(zer)] <- mean( zer,na.rm = T )
return( zer )
})
# select observation subset to make tutorial analyses run faster
# select 50 treatment and 50 control observations
set.seed(1.)
take_indices <- unlist( tapply(1:length(obsW),obsW,function(zer){sample(zer, 50)}) )
# set tfrecord save location (best to use absolute paths, but relative paths should in general work too)
tfrecord_loc <- "~/Downloads/ExampleRecord.tfrecord"
# write a tf records repository
causalimages::WriteTfRecord(  file = tfrecord_loc,
uniqueImageKeys = unique( as.character(KeysOfObservations)[ take_indices ] ),
acquireImageFxn = acquireImageFromMemory )
# perform causal inference with image and tabular confounding
# toy example for illustration purposes where
# treatment is truly randomized
ImageConfoundingAnalysis <- causalimages::AnalyzeImageConfounding(
obsW = obsW[ take_indices ],
obsY = obsY[ take_indices ],
X = X[ take_indices,apply(X[ take_indices,],2,sd)>0],
long = LongLat$geo_long[ take_indices ],
lat = LongLat$geo_lat[ take_indices ],
batchSize = 16L,
imageKeysOfUnits = as.character(KeysOfObservations)[ take_indices ],
file = tfrecord_loc, # point to tfrecords file
nSGD = 500L,
imageModelClass = "CNN",
#imageModelClass = "VisionTransformer",
plotBands = c(1,2,3),
figuresTag = "TutorialExample",
figuresPath = "~/Downloads/TFRecordTutorial" # figures saved here (use absolute file paths)
)
# perform causal inference with image and tabular confounding
# toy example for illustration purposes where
# treatment is truly randomized
ImageConfoundingAnalysis <- causalimages::AnalyzeImageConfounding(
obsW = obsW[ take_indices ],
obsY = obsY[ take_indices ],
X = X[ take_indices,apply(X[ take_indices,],2,sd)>0],
long = LongLat$geo_long[ take_indices ],
lat = LongLat$geo_lat[ take_indices ],
batchSize = 16L,
imageKeysOfUnits = as.character(KeysOfObservations)[ take_indices ],
file = tfrecord_loc, # point to tfrecords file
nSGD = 500L,
imageModelClass = "CNN",
#imageModelClass = "VisionTransformer",
plotBands = c(1,2,3),
figuresTag = "TutorialExample",
figuresPath = "~/Downloads/TFRecordTutorial" # figures saved here (use absolute file paths)
)
# perform causal inference with image and tabular confounding
# toy example for illustration purposes where
# treatment is truly randomized
ImageConfoundingAnalysis <- causalimages::AnalyzeImageConfounding(
obsW = obsW[ take_indices ],
obsY = obsY[ take_indices ],
X = X[ take_indices,apply(X[ take_indices,],2,sd)>0],
long = LongLat$geo_long[ take_indices ],
lat = LongLat$geo_lat[ take_indices ],
batchSize = 16L,
imageKeysOfUnits = as.character(KeysOfObservations)[ take_indices ],
file = tfrecord_loc, # point to tfrecords file
nSGD = 500L,
imageModelClass = "CNN",
#imageModelClass = "VisionTransformer",
plotBands = c(1,2,3),
figuresTag = "TutorialExample",
figuresPath = "~/Downloads/TFRecordTutorial" # figures saved here (use absolute file paths)
)
# perform causal inference with image and tabular confounding
# toy example for illustration purposes where
# treatment is truly randomized
ImageConfoundingAnalysis <- causalimages::AnalyzeImageConfounding(
obsW = obsW[ take_indices ],
obsY = obsY[ take_indices ],
X = X[ take_indices,apply(X[ take_indices,],2,sd)>0],
long = LongLat$geo_long[ take_indices ],
lat = LongLat$geo_lat[ take_indices ],
batchSize = 16L,
imageKeysOfUnits = as.character(KeysOfObservations)[ take_indices ],
file = tfrecord_loc, # point to tfrecords file
nSGD = 500L,
imageModelClass = "CNN",
#imageModelClass = "VisionTransformer",
plotBands = c(1,2,3),
figuresTag = "TutorialExample",
figuresPath = "~/Downloads/TFRecordTutorial" # figures saved here (use absolute file paths)
)
# perform causal inference with image and tabular confounding
# toy example for illustration purposes where
# treatment is truly randomized
ImageConfoundingAnalysis <- causalimages::AnalyzeImageConfounding(
obsW = obsW[ take_indices ],
obsY = obsY[ take_indices ],
X = X[ take_indices,apply(X[ take_indices,],2,sd)>0],
long = LongLat$geo_long[ take_indices ],
lat = LongLat$geo_lat[ take_indices ],
batchSize = 16L,
imageKeysOfUnits = as.character(KeysOfObservations)[ take_indices ],
file = tfrecord_loc, # point to tfrecords file
nSGD = 500L,
imageModelClass = "CNN",
#imageModelClass = "VisionTransformer",
plotBands = c(1,2,3),
figuresTag = "TutorialExample",
figuresPath = "~/Downloads/TFRecordTutorial" # figures saved here (use absolute file paths)
)
reticulate::py_last_error()
reticulate::py_last_error()$r_trace$full_call
ImageConfoundingAnalysis$tauHat_propensityHajek
#!/usr/bin/env Rscript
{
################################
# Image and image-sequence embeddings tutorial using causalimages
################################
# start with a clean environment
rm(list=ls()); options(error = NULL)
# remote install latest version of the package if needed
# devtools::install_github(repo = "cjerzak/causalimages-software/causalimages")
# local install for development team
# install.packages("~/Documents/causalimages-software/causalimages",repos = NULL, type = "source",force = F)
# build backend you haven't ready:
# causalimages::BuildBackend()
# load in package
library( causalimages  )
library(reticulate)
# load in tutorial data
data(  CausalImagesTutorialData )
# example acquire image function (loading from memory)
# in general, you'll want to write a function that returns images
# that saved disk associated with keys
acquireImageFromMemory <- function(keys){
# here, the function input keys
# refers to the unit-associated image keys
m_ <- FullImageArray[match(keys, KeysOfImages),,,]
# if keys == 1, add the batch dimension so output dims are always consistent
# (here in image case, dims are batch by height by width by channel)
if(length(keys) == 1){
m_ <- array(m_,dim = c(1L,dim(m_)[1],dim(m_)[2],dim(m_)[3]))
}
return( m_ )
}
# drop first column
X <- X[,-1]
# mean imputation for simplicity
X <- apply(X,2,function(zer){
zer[is.na(zer)] <- mean( zer,na.rm = T )
return( zer )
})
# select observation subset to make tutorial analyses run fast
take_indices <- unlist( tapply(1:length(obsW),obsW,function(zer){ sample(zer, 50) }) )
# write tf record
TfRecord_name <- "/Users/jspgr33n/Desktop/QTM-495/tutorials/CausalImagesTutorialDat.tfrecord"
causalimages::WriteTfRecord(  file =  TfRecord_name,
uniqueImageKeys = unique( KeysOfObservations[ take_indices ] ),
acquireImageFxn = acquireImageFromMemory  )
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L#,CleanupEnv = T
)
# sanity check - # of rows in MyImageEmbeddings matches # of image keys
nrow(MyImageEmbeddings_RandomProj$ImageRepresentations) == length(KeysOfObservations[ take_indices ])
# each row in MyImageEmbeddings$ImageRepresentations corresponds to an observation
# each column represents an embedding dimension associated with the imagery for that location
plot( MyImageEmbeddings_RandomProj$ImageRepresentations  )
# obtain image representation (pre-trained ViT)
MyImageEmbeddings_ViT <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
pretrainedModel = "vit-base",
imageKeysOfUnits = KeysOfObservations[ take_indices ]#,CleanupEnv = T
)
py# analyze ViT representations
plot( MyImageEmbeddings_ViT$ImageRepresentations  )
# obtain image representation (pre-trained CLIP-RCSID)
MyImageEmbeddings_Clip <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
pretrainedModel = "clip-rsicd",
imageKeysOfUnits = KeysOfObservations[ take_indices ],
CleanupEnv = T)
# analyze Clip representations
plot( MyImageEmbeddings_Clip$ImageRepresentations  )
# sanity check - # of rows in MyImageEmbeddings matches # of image keys
nrow(MyImageEmbeddings_Clip$ImageRepresentations) == length(KeysOfObservations[ take_indices ])
# other output quantities include the image model functions and model parameters
names(  MyImageEmbeddings_Clip  )[-1]
print("Done with image representations tutorial!")
}
# load in tutorial data
data(  CausalImagesTutorialData )
# example acquire image function (loading from memory)
# in general, you'll want to write a function that returns images
# that saved disk associated with keys
acquireImageFromMemory <- function(keys){
# here, the function input keys
# refers to the unit-associated image keys
m_ <- FullImageArray[match(keys, KeysOfImages),,,]
# if keys == 1, add the batch dimension so output dims are always consistent
# (here in image case, dims are batch by height by width by channel)
if(length(keys) == 1){
m_ <- array(m_,dim = c(1L,dim(m_)[1],dim(m_)[2],dim(m_)[3]))
}
return( m_ )
}
# drop first column
X <- X[,-1]
# mean imputation for simplicity
X <- apply(X,2,function(zer){
zer[is.na(zer)] <- mean( zer,na.rm = T )
return( zer )
})
# select observation subset to make tutorial analyses run fast
take_indices <- unlist( tapply(1:length(obsW),obsW,function(zer){ sample(zer, 50) }) )
# write tf record
TfRecord_name <- "/Users/jspgr33n/Desktop/QTM-495/tutorials/CausalImagesTutorialDat.tfrecord"
causalimages::WriteTfRecord(  file =  TfRecord_name,
uniqueImageKeys = unique( KeysOfObservations[ take_indices ] ),
acquireImageFxn = acquireImageFromMemory  )
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L#,CleanupEnv = T
)
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L,
CleanupEnv = T
)
nrow(MyImageEmbeddings_RandomProj$ImageRepresentations) == length(KeysOfObservations[ take_indices ])
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L#,CleanupEnv = T
)
TfRecord_name <- "/Users/jspgr33n/Desktop/QTM-495/tutorials/CausalImagesTutorialData.tfrecord"
causalimages::WriteTfRecord(  file =  TfRecord_name,
uniqueImageKeys = unique( KeysOfObservations[ take_indices ] ),
acquireImageFxn = acquireImageFromMemory  )
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L#,CleanupEnv = T
)
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L#,CleanupEnv = T
)
reticulate::py_last_error()
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L#,CleanupEnv = T
)
library( causalimages  )
library(reticulate)
data(  CausalImagesTutorialData )
# load in tutorial data
data(  CausalImagesTutorialData )
# example acquire image function (loading from memory)
# in general, you'll want to write a function that returns images
# that saved disk associated with keys
acquireImageFromMemory <- function(keys){
# here, the function input keys
# refers to the unit-associated image keys
m_ <- FullImageArray[match(keys, KeysOfImages),,,]
# if keys == 1, add the batch dimension so output dims are always consistent
# (here in image case, dims are batch by height by width by channel)
if(length(keys) == 1){
m_ <- array(m_,dim = c(1L,dim(m_)[1],dim(m_)[2],dim(m_)[3]))
}
return( m_ )
}
# drop first column
X <- X[,-1]
# mean imputation for simplicity
X <- apply(X,2,function(zer){
zer[is.na(zer)] <- mean( zer,na.rm = T )
return( zer )
})
# select observation subset to make tutorial analyses run fast
take_indices <- unlist( tapply(1:length(obsW),obsW,function(zer){ sample(zer, 50) }) )
# write tf record
TfRecord_name <- "/Users/jspgr33n/Desktop/QTM-495/tutorials/CausalImagesTutorialData.tfrecord"
causalimages::WriteTfRecord(  file =  TfRecord_name,
uniqueImageKeys = unique( KeysOfObservations[ take_indices ] ),
acquireImageFxn = acquireImageFromMemory  )
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L#,CleanupEnv = T
)
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L,
CleanupEnv = T
)
nrow(MyImageEmbeddings_RandomProj$ImageRepresentations) == length(KeysOfObservations[ take_indices ])
imageKeysOfUnits = KeysOfObservations[ take_indices ]
KeysOfObservations[ take_indices ]
TfRecord_name
len(KeysOfObservations)
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L,
CleanupEnv = T
)
# obtain image representation (pre-trained ViT)
MyImageEmbeddings_ViT <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
pretrainedModel = "vit-base",
imageKeysOfUnits = KeysOfObservations[ take_indices ]#,CleanupEnv = T
)
nrow(MyImageEmbeddings_RandomProj$ImageRepresentations) == length(KeysOfObservations[ take_indices ])
# obtain image representation (pre-trained CLIP-RCSID)
MyImageEmbeddings_Clip <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
pretrainedModel = "clip-rsicd",
imageKeysOfUnits = KeysOfObservations[ take_indices ],
CleanupEnv = T)
# obtain image representation (pre-trained ViT)
MyImageEmbeddings_ViT <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
pretrainedModel = "vit-base",
imageKeysOfUnits = KeysOfObservations[ take_indices ]#,CleanupEnv = T
)
# example acquire image function (loading from memory)
# in general, you'll want to write a function that returns images
# that saved disk associated with keys
acquireImageFromMemory <- function(keys){
# here, the function input keys
# refers to the unit-associated image keys
m_ <- FullImageArray[match(keys, KeysOfImages),,,]
# if keys == 1, add the batch dimension so output dims are always consistent
# (here in image case, dims are batch by height by width by channel)
if(length(keys) == 1){
m_ <- array(m_,dim = c(1L,dim(m_)[1],dim(m_)[2],dim(m_)[3]))
}
return( m_ )
}
acquireImageFromMemory
# write tf record
TfRecord_name <- "/Users/jspgr33n/Desktop/QTM-495/tutorials/CausalImagesTutorialData.tfrecord"
causalimages::WriteTfRecord(  file =  TfRecord_name,
uniqueImageKeys = unique( KeysOfObservations[ take_indices ] ),
acquireImageFxn = acquireImageFromMemory  )
# obtain image representation (random neural projection)
MyImageEmbeddings_RandomProj <- causalimages::GetImageRepresentations(
file  = TfRecord_name,
imageKeysOfUnits = KeysOfObservations[ take_indices ],
nDepth_ImageRep = 1L,
nWidth_ImageRep = 128L,
CleanupEnv = T
)
